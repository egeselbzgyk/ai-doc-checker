{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "# üìä Validation Set Batch Analysis - Aufgabe 4\n",
    "\n",
    "Bu notebook ile `dataset/val/SAP/` klas√∂r√ºndeki unlabeled g√∂rselleri:\n",
    "1. **EfficientNet-B0** ile classify edeceƒüiz\n",
    "2. **Qwen2.5 VL 32B Instruct** ile detaylƒ± analiz yapacaƒüƒ±z\n",
    "3. **Student submissions** i√ßin category statistics √ßƒ±karacaƒüƒ±z\n",
    "4. **Reference solution** adaylarƒ± belirleyeceƒüiz\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## üîß Setup ve Import'lar\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ All imports successful!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import base64\n",
    "import requests\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "import time\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Local imports\n",
    "from predict import predict_image\n",
    "from prompt_templates import prompt_templates\n",
    "\n",
    "print(\"‚úÖ All imports successful!\")\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## üéØ Qwen2.5 VL API Setup\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Qwen2.5 VL API initialized\n",
      "üéØ Ready to analyze images!\n"
     ]
    }
   ],
   "source": [
    "class QwenVLAnalyzer:\n",
    "    def __init__(self, hf_token=None):\n",
    "        \"\"\"\n",
    "        Qwen2.5 VL 32B Instruct API client\n",
    "        \n",
    "        Args:\n",
    "            hf_token: Hugging Face API token (eƒüer None ise environment'dan alƒ±r)\n",
    "        \"\"\"\n",
    "        self.api_url = \"https://api-inference.huggingface.co/models/Qwen/Qwen2.5-VL-32B-Instruct\"\n",
    "        \n",
    "        # Token setup\n",
    "        token = 'hf_token' or os.getenv('HF_TOKEN')\n",
    "        if not token:\n",
    "            raise ValueError(\"‚ùå Hugging Face token required! Set HF_TOKEN environment variable or pass hf_token parameter\")\n",
    "        \n",
    "        self.headers = {\n",
    "            \"Authorization\": f\"Bearer {token}\",\n",
    "            \"Content-Type\": \"application/json\"\n",
    "        }\n",
    "        \n",
    "        print(\"‚úÖ Qwen2.5 VL API initialized\")\n",
    "    \n",
    "    def encode_image(self, image_path):\n",
    "        \"\"\"G√∂rseli base64'e √ßevir\"\"\"\n",
    "        try:\n",
    "            with open(image_path, \"rb\") as image_file:\n",
    "                return base64.b64encode(image_file.read()).decode('utf-8')\n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Image encoding error: {e}\")\n",
    "            return None\n",
    "    \n",
    "    def analyze_image(self, image_path, prompt, max_retries=3):\n",
    "        \"\"\"Qwen2.5 VL ile g√∂rsel analizi\"\"\"\n",
    "        base64_image = self.encode_image(image_path)\n",
    "        if not base64_image:\n",
    "            return {\"error\": \"Failed to encode image\"}\n",
    "        \n",
    "        payload = {\n",
    "            \"inputs\": {\n",
    "                \"image\": base64_image,\n",
    "                \"text\": prompt\n",
    "            },\n",
    "            \"parameters\": {\n",
    "                \"max_new_tokens\": 1000,\n",
    "                \"temperature\": 0.1,  # Consistent results i√ßin d√º≈ü√ºk\n",
    "                \"do_sample\": False\n",
    "            }\n",
    "        }\n",
    "        \n",
    "        for attempt in range(max_retries):\n",
    "            try:\n",
    "                response = requests.post(self.api_url, headers=self.headers, json=payload, timeout=30)\n",
    "                \n",
    "                if response.status_code == 200:\n",
    "                    return response.json()\n",
    "                elif response.status_code == 503:  # Model loading\n",
    "                    print(f\"‚è≥ Model loading, waiting... (attempt {attempt + 1})\")\n",
    "                    time.sleep(20)\n",
    "                    continue\n",
    "                else:\n",
    "                    print(f\"‚ùå API Error: {response.status_code} - {response.text}\")\n",
    "                    return {\"error\": f\"API Error {response.status_code}: {response.text}\"}\n",
    "                    \n",
    "            except Exception as e:\n",
    "                print(f\"‚ùå Request error: {e}\")\n",
    "                if attempt < max_retries - 1:\n",
    "                    time.sleep(5)\n",
    "                    continue\n",
    "                return {\"error\": f\"Request failed: {str(e)}\"}\n",
    "        \n",
    "        return {\"error\": \"Max retries exceeded\"}\n",
    "    \n",
    "    def parse_json_response(self, response):\n",
    "        \"\"\"Qwen response'u JSON olarak parse et\"\"\"\n",
    "        try:\n",
    "            if \"error\" in response:\n",
    "                return response\n",
    "            \n",
    "            # Qwen response'undan text kƒ±smƒ±nƒ± al\n",
    "            text_output = \"\"\n",
    "            if isinstance(response, list) and len(response) > 0:\n",
    "                text_output = response[0].get('generated_text', '')\n",
    "            elif isinstance(response, dict):\n",
    "                text_output = response.get('generated_text', '')\n",
    "            \n",
    "            # JSON kƒ±smƒ±nƒ± extract et (curly braces arasƒ±nda)\n",
    "            start_idx = text_output.find('{')\n",
    "            end_idx = text_output.rfind('}') + 1\n",
    "            \n",
    "            if start_idx != -1 and end_idx > start_idx:\n",
    "                json_str = text_output[start_idx:end_idx]\n",
    "                return json.loads(json_str)\n",
    "            else:\n",
    "                return {\n",
    "                    \"error\": \"JSON not found in response\", \n",
    "                    \"raw_text\": text_output[:500]  # ƒ∞lk 500 char\n",
    "                }\n",
    "                \n",
    "        except json.JSONDecodeError as e:\n",
    "            return {\n",
    "                \"error\": f\"JSON parse error: {str(e)}\", \n",
    "                \"raw_response\": str(response)[:500]\n",
    "            }\n",
    "        except Exception as e:\n",
    "            return {\n",
    "                \"error\": f\"Unexpected error: {str(e)}\", \n",
    "                \"raw_response\": str(response)[:500]\n",
    "            }\n",
    "\n",
    "# Test the API setup\n",
    "try:\n",
    "    # HF token'ƒ± buraya girin veya environment variable olarak set edin\n",
    "    os.environ['HF_TOKEN'] = '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'\n",
    "    qwen_analyzer = QwenVLAnalyzer()\n",
    "    print(\"üéØ Ready to analyze images!\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Setup failed: {e}\")\n",
    "    print(\"üí° Set your HF token: os.environ['HF_TOKEN'] = 'your_token_here'\")\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## üóÇÔ∏è Dataset Kurulumu\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìÅ Validation directory: C:\\Users\\egese\\Desktop\\dataset\\val\\SAP\n",
      "üìä Total images found: 3135\n",
      "üíæ Output directory: results/validation_analysis/\n",
      "\n",
      "üìã Sample files:\n",
      "  1. 001e53127c8049dc94ead93b884b92fa.jpeg\n",
      "  2. 001e80166ed44602808dc75c92d81d3e.jpeg\n",
      "  3. 002f7cca46e7451797539bfc9520b39f.png\n",
      "  4. 0042c7e49bb143ca9b50b3d6336c003b.png\n",
      "  5. 0048fa9d132c47cf8e7b7e7a2397c340.png\n",
      "  ... and 3130 more\n"
     ]
    }
   ],
   "source": [
    "# Dataset paths\n",
    "VAL_DIR = r\"C:\\Users\\egese\\Desktop\\dataset\\val\\SAP\"\n",
    "OUTPUT_DIR = \"results/validation_analysis/\"\n",
    "\n",
    "# Output directory olu≈ütur\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "# Validation set'teki g√∂rselleri listele\n",
    "image_files = [f for f in os.listdir(VAL_DIR) \n",
    "               if f.lower().endswith(('.png', '.jpg', '.jpeg'))]\n",
    "\n",
    "print(f\"üìÅ Validation directory: {VAL_DIR}\")\n",
    "print(f\"üìä Total images found: {len(image_files)}\")\n",
    "print(f\"üíæ Output directory: {OUTPUT_DIR}\")\n",
    "\n",
    "# ƒ∞lk birka√ß dosya adƒ±nƒ± g√∂ster\n",
    "print(\"\\nüìã Sample files:\")\n",
    "for i, filename in enumerate(image_files[:5]):\n",
    "    print(f\"  {i+1}. {filename}\")\n",
    "if len(image_files) > 5:\n",
    "    print(f\"  ... and {len(image_files) - 5} more\")\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## üß™ Test Run - Tek G√∂rsel Analizi\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Testing with: 001e53127c8049dc94ead93b884b92fa.jpeg\n",
      "1Ô∏è‚É£ CNN Analysis...\n",
      "   ‚úÖ CNN Result: Info-Object (91.61% confidence)\n",
      "2Ô∏è‚É£ LLM Analysis...\n",
      "‚ùå API Error: 401 - {\"error\":\"Invalid credentials in Authorization header\"}\n",
      "   ‚úÖ LLM Analysis completed\n",
      "\n",
      "üìä ANALYSIS RESULTS:\n",
      "   Category: Info-Object\n",
      "   Confidence: 91.61%\n",
      "\n",
      "üéâ Test successful! Ready for batch processing.\n"
     ]
    }
   ],
   "source": [
    "def test_single_image_analysis(image_filename):\n",
    "    \"\"\"Tek g√∂rsel ile test analizi\"\"\"\n",
    "    image_path = os.path.join(VAL_DIR, image_filename)\n",
    "    \n",
    "    print(f\"üîç Testing with: {image_filename}\")\n",
    "    \n",
    "    try:\n",
    "        # 1. CNN Prediction\n",
    "        print(\"1Ô∏è‚É£ CNN Analysis...\")\n",
    "        predicted_class, confidence = predict_image(image_path)\n",
    "        print(f\"   ‚úÖ CNN Result: {predicted_class} ({confidence:.2%} confidence)\")\n",
    "        \n",
    "        # 2. LLM Analysis\n",
    "        print(\"2Ô∏è‚É£ LLM Analysis...\")\n",
    "        prompt = prompt_templates[predicted_class]\n",
    "        llm_response = qwen_analyzer.analyze_image(image_path, prompt)\n",
    "        llm_analysis = qwen_analyzer.parse_json_response(llm_response)\n",
    "        \n",
    "        print(\"   ‚úÖ LLM Analysis completed\")\n",
    "        \n",
    "        # 3. Results\n",
    "        result = {\n",
    "            \"filename\": image_filename,\n",
    "            \"cnn_prediction\": predicted_class,\n",
    "            \"cnn_confidence\": float(confidence),\n",
    "            \"llm_analysis\": llm_analysis,\n",
    "            \"timestamp\": datetime.now().isoformat(),\n",
    "            \"status\": \"success\"\n",
    "        }\n",
    "        \n",
    "        # Sonu√ßlarƒ± g√ºzel formatta yazdƒ±r\n",
    "        print(\"\\nüìä ANALYSIS RESULTS:\")\n",
    "        print(f\"   Category: {predicted_class}\")\n",
    "        print(f\"   Confidence: {confidence:.2%}\")\n",
    "        \n",
    "        if \"error\" not in llm_analysis:\n",
    "            if \"gesamt_score\" in llm_analysis:\n",
    "                print(f\"   LLM Score: {llm_analysis['gesamt_score']}/10\")\n",
    "            print(\"   LLM Analysis: ‚úÖ Success\")\n",
    "        else:\n",
    "            print(f\"   LLM Analysis: ‚ùå {llm_analysis['error']}\")\n",
    "        \n",
    "        return result\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Test failed: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "# Test ile ilk g√∂rsel\n",
    "if image_files:\n",
    "    test_result = test_single_image_analysis(image_files[0])\n",
    "    \n",
    "    if test_result and test_result.get('status') == 'success':\n",
    "        print(\"\\nüéâ Test successful! Ready for batch processing.\")\n",
    "    else:\n",
    "        print(\"\\n‚ö†Ô∏è Test failed. Please check configuration.\")\n",
    "else:\n",
    "    print(\"‚ùå No images found in validation directory!\")\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## üöÄ Batch Processing - T√ºm Validation Set\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ö° Choose your processing option:\n",
      "1. Test run (first 5 images)\n",
      "2. Medium run (first 20 images)\n",
      "3. Full run (all images)\n",
      "\n",
      "üöÄ Starting processing with limit: 5\n",
      "üîÑ Starting batch analysis of 5 images\n",
      "üíæ Saving intermediate results every 10 images\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing images:  20%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                                                    | 1/5 [00:01<00:04,  1.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ùå API Error: 401 - {\"error\":\"Invalid credentials in Authorization header\"}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing images:  40%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                                       | 2/5 [00:02<00:03,  1.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ùå API Error: 401 - {\"error\":\"Invalid credentials in Authorization header\"}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing images:  60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                          | 3/5 [00:03<00:02,  1.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ùå API Error: 401 - {\"error\":\"Invalid credentials in Authorization header\"}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing images:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà             | 4/5 [00:04<00:01,  1.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ùå API Error: 401 - {\"error\":\"Invalid credentials in Authorization header\"}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing images: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5/5 [00:05<00:00,  1.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ùå API Error: 401 - {\"error\":\"Invalid credentials in Authorization header\"}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def process_single_image(image_filename):\n",
    "    \"\"\"Tek g√∂rsel i√ßin tam analiz\"\"\"\n",
    "    image_path = os.path.join(VAL_DIR, image_filename)\n",
    "    \n",
    "    try:\n",
    "        # 1. CNN Prediction\n",
    "        predicted_class, confidence = predict_image(image_path)\n",
    "        \n",
    "        # 2. LLM Analysis\n",
    "        prompt = prompt_templates[predicted_class]\n",
    "        llm_response = qwen_analyzer.analyze_image(image_path, prompt)\n",
    "        llm_analysis = qwen_analyzer.parse_json_response(llm_response)\n",
    "        \n",
    "        result = {\n",
    "            \"filename\": image_filename,\n",
    "            \"image_path\": image_path,\n",
    "            \"cnn_prediction\": predicted_class,\n",
    "            \"cnn_confidence\": float(confidence),\n",
    "            \"llm_analysis\": llm_analysis,\n",
    "            \"timestamp\": datetime.now().isoformat(),\n",
    "            \"status\": \"success\"\n",
    "        }\n",
    "        \n",
    "        return result\n",
    "        \n",
    "    except Exception as e:\n",
    "        return {\n",
    "            \"filename\": image_filename,\n",
    "            \"status\": \"error\",\n",
    "            \"error\": str(e),\n",
    "            \"timestamp\": datetime.now().isoformat()\n",
    "        }\n",
    "\n",
    "def run_batch_analysis(limit=None, save_every=10):\n",
    "    \"\"\"Batch analiz - t√ºm validation set\"\"\"\n",
    "    \n",
    "    # Limit uygula\n",
    "    files_to_process = image_files[:limit] if limit else image_files\n",
    "    \n",
    "    print(f\"üîÑ Starting batch analysis of {len(files_to_process)} images\")\n",
    "    print(f\"üíæ Saving intermediate results every {save_every} images\")\n",
    "    \n",
    "    all_results = []\n",
    "    \n",
    "    # Progress bar ile i≈ülem\n",
    "    for i, image_file in enumerate(tqdm(files_to_process, desc=\"Processing images\")):\n",
    "        \n",
    "        result = process_single_image(image_file)\n",
    "        all_results.append(result)\n",
    "        \n",
    "        # Interim save\n",
    "        if (i + 1) % save_every == 0:\n",
    "            interim_filename = f\"interim_results_{i+1}.json\"\n",
    "            interim_path = os.path.join(OUTPUT_DIR, interim_filename)\n",
    "            \n",
    "            with open(interim_path, 'w', encoding='utf-8') as f:\n",
    "                json.dump(all_results, f, ensure_ascii=False, indent=2)\n",
    "            \n",
    "            # Progress info\n",
    "            success_count = len([r for r in all_results if r.get('status') == 'success'])\n",
    "            print(f\"\\nüìä Progress: {i+1}/{len(files_to_process)} | Success: {success_count} | Saved: {interim_filename}\")\n",
    "    \n",
    "    return all_results\n",
    "\n",
    "# BATCH PROCESSING BA≈ûLAT\n",
    "print(\"‚ö° Choose your processing option:\")\n",
    "print(\"1. Test run (first 5 images)\")\n",
    "print(\"2. Medium run (first 20 images)\")\n",
    "print(\"3. Full run (all images)\")\n",
    "\n",
    "# Test run ile ba≈üla - Bu deƒüeri deƒüi≈ütirerek full run yapabilirsiniz\n",
    "PROCESSING_LIMIT = 5  \n",
    "\n",
    "print(f\"\\nüöÄ Starting processing with limit: {PROCESSING_LIMIT}\")\n",
    "batch_results = run_batch_analysis(limit=PROCESSING_LIMIT)\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## üíæ Sonu√ßlarƒ± Kaydetme\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final sonu√ßlarƒ± kaydet\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "final_filename = f\"validation_batch_results_{timestamp}.json\"\n",
    "final_path = os.path.join(OUTPUT_DIR, final_filename)\n",
    "\n",
    "with open(final_path, 'w', encoding='utf-8') as f:\n",
    "    json.dump(batch_results, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "print(f\"‚úÖ Final results saved: {final_path}\")\n",
    "print(f\"üìÅ File size: {os.path.getsize(final_path) / 1024:.1f} KB\")\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## üìä Sonu√ß Analizi ve ƒ∞statistikler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_batch_results(results):\n",
    "    \"\"\"Batch sonu√ßlarƒ±nƒ±n detaylƒ± analizi\"\"\"\n",
    "    \n",
    "    successful_results = [r for r in results if r.get('status') == 'success']\n",
    "    error_count = len(results) - len(successful_results)\n",
    "    \n",
    "    print(\"=\"*60)\n",
    "    print(\"üìä VALIDATION SET ANALYSIS REPORT\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    print(f\"\\nüìà Processing Summary:\")\n",
    "    print(f\"   Total Images: {len(results)}\")\n",
    "    print(f\"   Successful: {len(successful_results)}\")\n",
    "    print(f\"   Errors: {error_count}\")\n",
    "    print(f\"   Success Rate: {len(successful_results)/len(results)*100:.1f}%\")\n",
    "    \n",
    "    if not successful_results:\n",
    "        print(\"‚ùå No successful results to analyze!\")\n",
    "        return\n",
    "    \n",
    "    # Kategori istatistikleri\n",
    "    category_stats = {}\n",
    "    all_confidences = []\n",
    "    all_llm_scores = []\n",
    "    \n",
    "    for result in successful_results:\n",
    "        category = result['cnn_prediction']\n",
    "        confidence = result['cnn_confidence']\n",
    "        all_confidences.append(confidence)\n",
    "        \n",
    "        if category not in category_stats:\n",
    "            category_stats[category] = {\n",
    "                'count': 0,\n",
    "                'confidences': [],\n",
    "                'gesamt_scores': [],\n",
    "                'llm_success_rate': 0\n",
    "            }\n",
    "        \n",
    "        category_stats[category]['count'] += 1\n",
    "        category_stats[category]['confidences'].append(confidence)\n",
    "        \n",
    "        # LLM analysis kontrol et\n",
    "        llm_analysis = result.get('llm_analysis', {})\n",
    "        if 'error' not in llm_analysis and 'gesamt_score' in llm_analysis:\n",
    "            score = llm_analysis['gesamt_score']\n",
    "            category_stats[category]['gesamt_scores'].append(score)\n",
    "            all_llm_scores.append(score)\n",
    "    \n",
    "    # Kategori ba≈üƒ±na istatistikler\n",
    "    print(f\"\\nüîç Category Analysis:\")\n",
    "    print(\"-\" * 60)\n",
    "    \n",
    "    for category, stats in sorted(category_stats.items()):\n",
    "        avg_conf = sum(stats['confidences']) / len(stats['confidences'])\n",
    "        avg_score = sum(stats['gesamt_scores']) / len(stats['gesamt_scores']) if stats['gesamt_scores'] else 0\n",
    "        llm_success = len(stats['gesamt_scores']) / stats['count'] * 100\n",
    "        \n",
    "        print(f\"\\nüìÅ {category}:\")\n",
    "        print(f\"   Images: {stats['count']}\")\n",
    "        print(f\"   Avg CNN Confidence: {avg_conf:.2%}\")\n",
    "        print(f\"   Avg LLM Score: {avg_score:.1f}/10\")\n",
    "        print(f\"   LLM Success Rate: {llm_success:.1f}%\")\n",
    "    \n",
    "    # Genel istatistikler\n",
    "    print(f\"\\nüìä Overall Statistics:\")\n",
    "    print(\"-\" * 30)\n",
    "    if all_confidences:\n",
    "        print(f\"   Avg CNN Confidence: {sum(all_confidences)/len(all_confidences):.2%}\")\n",
    "        print(f\"   Min CNN Confidence: {min(all_confidences):.2%}\")\n",
    "        print(f\"   Max CNN Confidence: {max(all_confidences):.2%}\")\n",
    "    \n",
    "    if all_llm_scores:\n",
    "        print(f\"   Avg LLM Score: {sum(all_llm_scores)/len(all_llm_scores):.1f}/10\")\n",
    "        print(f\"   Min LLM Score: {min(all_llm_scores):.1f}/10\")\n",
    "        print(f\"   Max LLM Score: {max(all_llm_scores):.1f}/10\")\n",
    "    \n",
    "    return category_stats\n",
    "\n",
    "# Analizi √ßalƒ±≈ütƒ±r\n",
    "category_statistics = analyze_batch_results(batch_results)\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## üéØ Reference Solution Candidates\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def identify_reference_candidates(results, top_n=3):\n",
    "    \"\"\"Her kategoriden en iyi √∂rnekleri referans aday olarak se√ß\"\"\"\n",
    "    \n",
    "    successful_results = [r for r in results if r.get('status') == 'success']\n",
    "    \n",
    "    if not successful_results:\n",
    "        print(\"‚ùå No successful results for reference selection!\")\n",
    "        return {}\n",
    "    \n",
    "    reference_candidates = {}\n",
    "    \n",
    "    # Kategori ba≈üƒ±na grup\n",
    "    by_category = {}\n",
    "    for result in successful_results:\n",
    "        category = result['cnn_prediction']\n",
    "        if category not in by_category:\n",
    "            by_category[category] = []\n",
    "        by_category[category].append(result)\n",
    "    \n",
    "    print(\"üéØ REFERENCE SOLUTION CANDIDATES\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    for category, items in by_category.items():\n",
    "        print(f\"\\nüìÅ {category} ({len(items)} images):\")\n",
    "        \n",
    "        # Kombinasyon skoru: CNN confidence + LLM score\n",
    "        scored_items = []\n",
    "        for item in items:\n",
    "            cnn_conf = item['cnn_confidence']\n",
    "            llm_analysis = item.get('llm_analysis', {})\n",
    "            \n",
    "            if 'error' not in llm_analysis and 'gesamt_score' in llm_analysis:\n",
    "                llm_score = llm_analysis['gesamt_score'] / 10  # 0-1 aralƒ±ƒüƒ±na normalize\n",
    "                combined_score = (cnn_conf * 0.4) + (llm_score * 0.6)  # LLM'e aƒüƒ±rlƒ±k ver\n",
    "            else:\n",
    "                combined_score = cnn_conf * 0.7  # Sadece CNN score\n",
    "            \n",
    "            scored_items.append((item, combined_score))\n",
    "        \n",
    "        # En y√ºksek skorlular\n",
    "        top_items = sorted(scored_items, key=lambda x: x[1], reverse=True)[:top_n]\n",
    "        reference_candidates[category] = []\n",
    "        \n",
    "        for i, (item, score) in enumerate(top_items, 1):\n",
    "            reference_candidates[category].append(item)\n",
    "            \n",
    "            llm_info = \"\"\n",
    "            llm_analysis = item.get('llm_analysis', {})\n",
    "            if 'gesamt_score' in llm_analysis:\n",
    "                llm_info = f\", LLM: {llm_analysis['gesamt_score']:.1f}/10\"\n",
    "            \n",
    "            print(f\"   {i}. {item['filename']}\")\n",
    "            print(f\"      Score: {score:.3f} (CNN: {item['cnn_confidence']:.2%}{llm_info})\")\n",
    "    \n",
    "    return reference_candidates\n",
    "\n",
    "# Reference candidates se√ß\n",
    "reference_candidates = identify_reference_candidates(batch_results, top_n=3)\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## üíæ Reference Candidates Kaydetme\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reference candidates'ƒ± ayrƒ± dosyaya kaydet\n",
    "reference_filename = f\"reference_candidates_{timestamp}.json\"\n",
    "reference_path = os.path.join(OUTPUT_DIR, reference_filename)\n",
    "\n",
    "with open(reference_path, 'w', encoding='utf-8') as f:\n",
    "    json.dump(reference_candidates, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "print(f\"‚úÖ Reference candidates saved: {reference_path}\")\n",
    "\n",
    "# Summary raporu\n",
    "summary = {\n",
    "    \"analysis_timestamp\": timestamp,\n",
    "    \"total_images_processed\": len(batch_results),\n",
    "    \"successful_analyses\": len([r for r in batch_results if r.get('status') == 'success']),\n",
    "    \"categories_found\": list(reference_candidates.keys()),\n",
    "    \"reference_candidates_per_category\": {k: len(v) for k, v in reference_candidates.items()},\n",
    "    \"files_generated\": {\n",
    "        \"full_results\": final_filename,\n",
    "        \"reference_candidates\": reference_filename\n",
    "    }\n",
    "}\n",
    "\n",
    "summary_filename = f\"analysis_summary_{timestamp}.json\"\n",
    "summary_path = os.path.join(OUTPUT_DIR, summary_filename)\n",
    "\n",
    "with open(summary_path, 'w', encoding='utf-8') as f:\n",
    "    json.dump(summary, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "print(f\"üìã Summary saved: {summary_path}\")\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## üéâ Sonu√ß ve Sonraki Adƒ±mlar\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"üéâ VALIDATION SET ANALYSIS COMPLETED!\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "print(f\"\\nüìä Analysis Summary:\")\n",
    "print(f\"   ‚úÖ Processed: {len(batch_results)} images\")\n",
    "print(f\"   üìÅ Categories found: {len(reference_candidates)} categories\")\n",
    "print(f\"   üéØ Reference candidates: {sum(len(v) for v in reference_candidates.values())} total\")\n",
    "\n",
    "print(f\"\\nüíæ Files Generated:\")\n",
    "print(f\"   üìÑ {final_filename} - Full analysis results\")\n",
    "print(f\"   üéØ {reference_filename} - Reference solution candidates\")\n",
    "print(f\"   üìã {summary_filename} - Analysis summary\")\n",
    "\n",
    "print(f\"\\nüöÄ Next Steps for Aufgabe 4:\")\n",
    "print(f\"   1Ô∏è‚É£ Review reference candidates manually\")\n",
    "print(f\"   2Ô∏è‚É£ Select final Musterl√∂sung for each category\")\n",
    "print(f\"   3Ô∏è‚É£ Implement comparison engine\")\n",
    "print(f\"   4Ô∏è‚É£ Test student vs reference comparison\")\n",
    "\n",
    "print(f\"\\nüí° Tips:\")\n",
    "print(f\"   ‚Ä¢ High CNN confidence + High LLM score = Good reference candidate\")\n",
    "print(f\"   ‚Ä¢ Check images manually before using as Musterl√∂sung\")\n",
    "print(f\"   ‚Ä¢ Use comparison_prompt from prompt_templates.py for next step\")\n",
    "\n",
    "print(\"\\nüîß Ready for Aufgabe 4 - Comparison Engine Implementation!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "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"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
