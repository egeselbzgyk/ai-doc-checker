{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "# ğŸ¯ Reference Solution Selection Tool - MusterlÃ¶sung SeÃ§imi\n",
    "\n",
    "Bu notebook ile **eÄŸitim verilerinden** (mapped_train) en iyi referans Ã§Ã¶zÃ¼mleri seÃ§eceÄŸiz:\n",
    "1. **EÄŸitim verilerini** (mapped_train) analiz edeceÄŸiz\n",
    "2. Her kategori iÃ§in **en kaliteli Ã¶rnekleri** belirleyeceÄŸiz\n",
    "3. **Manuel review** ile final **MusterlÃ¶sung** seÃ§eceÄŸiz\n",
    "4. **Reference database** oluÅŸturacaÄŸÄ±z\n",
    "\n",
    "âš ï¸ **Ã–nemli:** Referans Ã§Ã¶zÃ¼mler Ã¶ÄŸrenci Ã§Ã¶zÃ¼mlerinden (val/SAP) deÄŸil, eÄŸitim verilerinden (mapped_train) seÃ§ilmelidir!\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## ğŸ”§ Setup ve Import'lar\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… All imports successful!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from PIL import Image\n",
    "from datetime import datetime\n",
    "import warnings\n",
    "import random\n",
    "from collections import defaultdict\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Local imports\n",
    "from predict import predict_image\n",
    "from prompt_templates import prompt_templates\n",
    "\n",
    "print(\"âœ… All imports successful!\")\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## ğŸ“ Dizin YapÄ±landÄ±rmasÄ± ve Kategori TanÄ±mlarÄ±\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DoÄŸru veri kaynaklarÄ±\n",
    "TRAINING_DIR = r\"C:\\Users\\egese\\Desktop\\dataset\\mapped_train\"  # EÄŸitim verileri (MusterlÃ¶sung adaylarÄ±)\n",
    "VAL_DIR = r\"C:\\Users\\egese\\Desktop\\dataset\\val\\SAP\"          # Ã–ÄŸrenci Ã§Ã¶zÃ¼mleri (sadece test iÃ§in)\n",
    "REFERENCE_OUTPUT = \"results/reference_solutions/\"  # SeÃ§ilen referanslar\n",
    "ANALYSIS_OUTPUT = \"results/reference_analysis/\"    # Analiz sonuÃ§larÄ±\n",
    "\n",
    "# Output directories oluÅŸtur\n",
    "os.makedirs(REFERENCE_OUTPUT, exist_ok=True)\n",
    "os.makedirs(ANALYSIS_OUTPUT, exist_ok=True)\n",
    "\n",
    "# SAP BW kategorileri\n",
    "CATEGORIES = [\n",
    "    \"Data Source\",\n",
    "    \"Data-Flow\", \n",
    "    \"Data-Transfer-Process\",\n",
    "    \"Excel-Tabelle\",\n",
    "    \"Info-Object\", \n",
    "    \"Transformation\"\n",
    "]\n",
    "\n",
    "print(f\"ğŸ“ Training directory: {TRAINING_DIR}\")\n",
    "print(f\"ğŸ“ Validation directory: {VAL_DIR}\")\n",
    "print(f\"ğŸ’¾ Reference output: {REFERENCE_OUTPUT}\")\n",
    "print(f\"ğŸ“Š Analysis output: {ANALYSIS_OUTPUT}\")\n",
    "print(f\"\\nğŸ“‹ Categories to analyze: {len(CATEGORIES)}\")\n",
    "for i, cat in enumerate(CATEGORIES, 1):\n",
    "    print(f\"  {i}. {cat}\")\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## ğŸ” EÄŸitim Verilerini Analiz Et\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_training_data():\n",
    "    \"\"\"EÄŸitim verilerindeki kategori daÄŸÄ±lÄ±mÄ±nÄ± analiz et\"\"\"\n",
    "    category_stats = {}\n",
    "    \n",
    "    print(\"ğŸ” Analyzing training data structure...\\n\")\n",
    "    \n",
    "    for category in CATEGORIES:\n",
    "        category_path = os.path.join(TRAINING_DIR, category)\n",
    "        \n",
    "        if os.path.exists(category_path):\n",
    "            # GÃ¶rÃ¼ntÃ¼ dosyalarÄ±nÄ± say\n",
    "            image_files = [f for f in os.listdir(category_path) \n",
    "                          if f.lower().endswith(('.png', '.jpg', '.jpeg'))]\n",
    "            \n",
    "            category_stats[category] = {\n",
    "                'count': len(image_files),\n",
    "                'files': image_files[:5],  # Ä°lk 5 dosya Ã¶rneÄŸi\n",
    "                'path': category_path\n",
    "            }\n",
    "            \n",
    "            print(f\"ğŸ“‚ {category}:\")\n",
    "            print(f\"   ğŸ“Š Total images: {len(image_files)}\")\n",
    "            print(f\"   ğŸ“‹ Sample files: {image_files[:3]}\")\n",
    "            if len(image_files) > 3:\n",
    "                print(f\"       ... and {len(image_files) - 3} more\")\n",
    "            print()\n",
    "        else:\n",
    "            print(f\"âŒ Category not found: {category_path}\")\n",
    "            category_stats[category] = {'count': 0, 'files': [], 'path': category_path}\n",
    "    \n",
    "    return category_stats\n",
    "\n",
    "# EÄŸitim verilerini analiz et\n",
    "training_stats = analyze_training_data()\n",
    "\n",
    "# Ã–zet istatistikler\n",
    "total_images = sum(stats['count'] for stats in training_stats.values())\n",
    "available_categories = sum(1 for stats in training_stats.values() if stats['count'] > 0)\n",
    "\n",
    "print(f\"ğŸ“Š SUMMARY:\")\n",
    "print(f\"   Total training images: {total_images}\")\n",
    "print(f\"   Available categories: {available_categories}/{len(CATEGORIES)}\")\n",
    "print(f\"   Average per category: {total_images/len(CATEGORIES):.1f}\")\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## ğŸ¯ Referans Aday DeÄŸerlendirme Sistemi\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_reference_candidate(image_path, category):\n",
    "    \"\"\"Referans aday iÃ§in kapsamlÄ± deÄŸerlendirme\"\"\"\n",
    "    try:\n",
    "        # 1. GÃ¶rÃ¼ntÃ¼ kalitesi kontrolÃ¼\n",
    "        img = Image.open(image_path)\n",
    "        width, height = img.size\n",
    "        \n",
    "        # GÃ¶rÃ¼ntÃ¼ kalitesi puanÄ±\n",
    "        quality_score = 0\n",
    "        if width >= 800 and height >= 600:\n",
    "            quality_score += 3\n",
    "        elif width >= 600 and height >= 400:\n",
    "            quality_score += 2\n",
    "        else:\n",
    "            quality_score += 1\n",
    "            \n",
    "        # Aspect ratio kontrolÃ¼\n",
    "        aspect_ratio = width / height\n",
    "        if 1.2 <= aspect_ratio <= 2.0:  # Normal ekran oranlarÄ±\n",
    "            quality_score += 2\n",
    "        \n",
    "        # 2. CNN sÄ±nÄ±flandÄ±rma gÃ¼venilirliÄŸi\n",
    "        predicted_class, confidence = predict_image(image_path)\n",
    "        \n",
    "        # Kategori uyumu kontrolÃ¼\n",
    "        category_match = (predicted_class == category)\n",
    "        confidence_score = int(confidence * 10)  # 0-10 arasÄ±\n",
    "        \n",
    "        # 3. Dosya boyutu ve format kontrolÃ¼\n",
    "        file_size = os.path.getsize(image_path) / (1024 * 1024)  # MB\n",
    "        format_score = 2 if img.format in ['PNG', 'JPEG'] else 1\n",
    "        size_score = 2 if 0.1 <= file_size <= 5.0 else 1\n",
    "        \n",
    "        # 4. Toplam puan hesaplama\n",
    "        total_score = (\n",
    "            quality_score * 0.3 +\n",
    "            confidence_score * 0.4 +\n",
    "            (10 if category_match else 0) * 0.2 +\n",
    "            (format_score + size_score) * 0.1\n",
    "        )\n",
    "        \n",
    "        return {\n",
    "            'image_path': image_path,\n",
    "            'filename': os.path.basename(image_path),\n",
    "            'category': category,\n",
    "            'predicted_class': predicted_class,\n",
    "            'confidence': confidence,\n",
    "            'category_match': category_match,\n",
    "            'dimensions': f\"{width}x{height}\",\n",
    "            'file_size_mb': round(file_size, 2),\n",
    "            'format': img.format,\n",
    "            'quality_score': quality_score,\n",
    "            'confidence_score': confidence_score,\n",
    "            'total_score': round(total_score, 2),\n",
    "            'evaluation_date': datetime.now().isoformat()\n",
    "        }\n",
    "        \n",
    "    except Exception as e:\n",
    "        return {\n",
    "            'image_path': image_path,\n",
    "            'filename': os.path.basename(image_path),\n",
    "            'category': category,\n",
    "            'error': str(e),\n",
    "            'total_score': 0,\n",
    "            'evaluation_date': datetime.now().isoformat()\n",
    "        }\n",
    "\n",
    "def evaluate_category_candidates(category, max_samples=None):\n",
    "    \"\"\"Bir kategori iÃ§in tÃ¼m adaylarÄ± deÄŸerlendir\"\"\"\n",
    "    category_path = os.path.join(TRAINING_DIR, category)\n",
    "    \n",
    "    if not os.path.exists(category_path):\n",
    "        print(f\"âŒ Category path not found: {category_path}\")\n",
    "        return []\n",
    "    \n",
    "    # GÃ¶rÃ¼ntÃ¼ dosyalarÄ±nÄ± al\n",
    "    image_files = [f for f in os.listdir(category_path) \n",
    "                   if f.lower().endswith(('.png', '.jpg', '.jpeg'))]\n",
    "    \n",
    "    # Sampling yapmak istiyorsak\n",
    "    if max_samples and len(image_files) > max_samples:\n",
    "        image_files = random.sample(image_files, max_samples)\n",
    "    \n",
    "    print(f\"ğŸ” Evaluating {len(image_files)} candidates for {category}...\")\n",
    "    \n",
    "    candidates = []\n",
    "    for i, filename in enumerate(image_files, 1):\n",
    "        image_path = os.path.join(category_path, filename)\n",
    "        evaluation = evaluate_reference_candidate(image_path, category)\n",
    "        candidates.append(evaluation)\n",
    "        \n",
    "        if i % 10 == 0:\n",
    "            print(f\"   Progress: {i}/{len(image_files)} ({i/len(image_files)*100:.1f}%)\")\n",
    "    \n",
    "    # Puana gÃ¶re sÄ±rala\n",
    "    candidates.sort(key=lambda x: x.get('total_score', 0), reverse=True)\n",
    "    \n",
    "    print(f\"âœ… Evaluation completed for {category}\")\n",
    "    return candidates\n",
    "\n",
    "print(\"ğŸ¯ Reference evaluation system ready!\")\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## ğŸš€ TÃ¼m Kategoriler Ä°Ã§in Aday DeÄŸerlendirmesi\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_full_evaluation(max_samples_per_category=20):\n",
    "    \"\"\"TÃ¼m kategoriler iÃ§in referans aday deÄŸerlendirmesi\"\"\"\n",
    "    all_evaluations = {}\n",
    "    \n",
    "    print(f\"ğŸš€ Starting full evaluation (max {max_samples_per_category} samples per category)\\n\")\n",
    "    \n",
    "    for i, category in enumerate(CATEGORIES, 1):\n",
    "        print(f\"\\nğŸ“‚ [{i}/{len(CATEGORIES)}] Processing: {category}\")\n",
    "        print(\"=\"*50)\n",
    "        \n",
    "        candidates = evaluate_category_candidates(category, max_samples_per_category)\n",
    "        all_evaluations[category] = candidates\n",
    "        \n",
    "        if candidates:\n",
    "            # En iyi 3 adayÄ± gÃ¶ster\n",
    "            print(f\"\\nğŸ† Top 3 candidates for {category}:\")\n",
    "            for j, candidate in enumerate(candidates[:3], 1):\n",
    "                score = candidate.get('total_score', 0)\n",
    "                confidence = candidate.get('confidence', 0)\n",
    "                match = candidate.get('category_match', False)\n",
    "                print(f\"   {j}. {candidate['filename']} - Score: {score:.2f} - Confidence: {confidence:.2%} - Match: {'âœ…' if match else 'âŒ'}\")\n",
    "        else:\n",
    "            print(f\"âŒ No valid candidates found for {category}\")\n",
    "    \n",
    "    return all_evaluations\n",
    "\n",
    "# DeÄŸerlendirmeyi Ã§alÄ±ÅŸtÄ±r\n",
    "evaluations = run_full_evaluation(max_samples_per_category=15)\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## ğŸ“Š Otomatik Top 5 SeÃ§imi ve JSON Export\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_reference_database_auto(evaluations, top_n=5):\n",
    "    \"\"\"Otomatik olarak her kategoriden top N seÃ§imi yapÄ±p JSON olarak kaydet\"\"\"\n",
    "    \n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    \n",
    "    # Reference database oluÅŸtur\n",
    "    reference_database = {\n",
    "        'selection_date': datetime.now().isoformat(),\n",
    "        'selection_method': 'automatic_top_candidates',\n",
    "        'top_candidates_per_category': top_n,\n",
    "        'total_categories': len(CATEGORIES),\n",
    "        'selected_categories': 0,\n",
    "        'references': {}\n",
    "    }\n",
    "    \n",
    "    print(f\"ğŸ“Š Creating automatic reference database (Top {top_n} per category)...\\n\")\n",
    "    \n",
    "    selected_count = 0\n",
    "    for category, candidates in evaluations.items():\n",
    "        valid_candidates = [c for c in candidates if 'error' not in c]\n",
    "        \n",
    "        if valid_candidates:\n",
    "            # Top N seÃ§\n",
    "            top_candidates = valid_candidates[:top_n]\n",
    "            reference_database['references'][category] = top_candidates\n",
    "            selected_count += 1\n",
    "            \n",
    "            print(f\"ğŸ“‚ {category} - Selected top {len(top_candidates)} candidates:\")\n",
    "            for i, candidate in enumerate(top_candidates, 1):\n",
    "                score = candidate.get('total_score', 0)\n",
    "                confidence = candidate.get('confidence', 0)\n",
    "                match = candidate.get('category_match', False)\n",
    "                print(f\"   {i}. {candidate['filename']} (Score: {score:.2f}, Confidence: {confidence:.2%}, Match: {'âœ…' if match else 'âŒ'})\")\n",
    "            print()\n",
    "        else:\n",
    "            print(f\"âŒ No valid candidates for {category}\")\n",
    "            reference_database['references'][category] = []\n",
    "    \n",
    "    reference_database['selected_categories'] = selected_count\n",
    "    \n",
    "    # JSON olarak kaydet\n",
    "    db_filename = f\"reference_database_auto_{timestamp}.json\"\n",
    "    db_path = os.path.join(REFERENCE_OUTPUT, db_filename)\n",
    "    \n",
    "    with open(db_path, 'w', encoding='utf-8') as f:\n",
    "        json.dump(reference_database, f, ensure_ascii=False, indent=2)\n",
    "    \n",
    "    # Latest olarak da kaydet (kolay eriÅŸim iÃ§in)\n",
    "    latest_path = os.path.join(REFERENCE_OUTPUT, \"reference_database_latest.json\")\n",
    "    with open(latest_path, 'w', encoding='utf-8') as f:\n",
    "        json.dump(reference_database, f, ensure_ascii=False, indent=2)\n",
    "    \n",
    "    # Summary oluÅŸtur\n",
    "    summary = {\n",
    "        'evaluation_summary': {\n",
    "            'timestamp': timestamp,\n",
    "            'method': 'automatic_selection_simple_metrics',\n",
    "            'categories_processed': len(CATEGORIES),\n",
    "            'categories_with_candidates': selected_count,\n",
    "            'top_candidates_per_category': top_n,\n",
    "            'total_candidates_selected': sum(len(refs) for refs in reference_database['references'].values())\n",
    "        },\n",
    "        'score_statistics': {},\n",
    "        'files_generated': {\n",
    "            'reference_database': db_filename,\n",
    "            'latest_database': 'reference_database_latest.json'\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    # Her kategori iÃ§in istatistik\n",
    "    for category, candidates in evaluations.items():\n",
    "        valid_candidates = [c for c in candidates if 'error' not in c and 'total_score' in c]\n",
    "        if valid_candidates:\n",
    "            scores = [c['total_score'] for c in valid_candidates]\n",
    "            summary['score_statistics'][category] = {\n",
    "                'total_candidates_evaluated': len(valid_candidates),\n",
    "                'avg_score': round(sum(scores) / len(scores), 2),\n",
    "                'max_score': round(max(scores), 2),\n",
    "                'min_score': round(min(scores), 2),\n",
    "                'top_5_selected': len(reference_database['references'][category])\n",
    "            }\n",
    "    \n",
    "    summary_filename = f\"reference_selection_summary_{timestamp}.json\"\n",
    "    summary_path = os.path.join(ANALYSIS_OUTPUT, summary_filename)\n",
    "    \n",
    "    with open(summary_path, 'w', encoding='utf-8') as f:\n",
    "        json.dump(summary, f, ensure_ascii=False, indent=2)\n",
    "    \n",
    "    print(f\"âœ… Reference database saved: {db_path}\")\n",
    "    print(f\"ğŸ“‹ Latest database: {latest_path}\")\n",
    "    print(f\"ğŸ“Š Summary saved: {summary_path}\")\n",
    "    \n",
    "    return reference_database, summary\n",
    "\n",
    "print(\"ğŸ“Š Automatic reference selection system ready!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Otomatik referans seÃ§imi yap\n",
    "reference_db, selection_summary = create_reference_database_auto(evaluations, top_n=5)\n",
    "\n",
    "print(f\"\\nğŸ‰ AUTOMATIC SELECTION COMPLETED!\")\n",
    "print(f\"ğŸ“Š Reference database created with top 5 candidates per category\")\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## ğŸ“‹ SonuÃ§lar ve Ã–zet Rapor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"ğŸ¯ REFERENCE SELECTION COMPLETED!\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(f\"\\nâœ… What was accomplished:\")\n",
    "print(f\"   1. Analyzed training data from {len(CATEGORIES)} categories\")\n",
    "print(f\"   2. Evaluated candidates using CNN confidence + quality metrics\")\n",
    "print(f\"   3. Automatically selected top 5 candidates per category\")\n",
    "print(f\"   4. Created JSON reference database\")\n",
    "print(f\"   5. Generated summary statistics\")\n",
    "\n",
    "print(f\"\\nğŸ“Š Selection Results:\")\n",
    "total_selected = sum(len(refs) for refs in reference_db['references'].values())\n",
    "print(f\"   Categories processed: {len(CATEGORIES)}\")\n",
    "print(f\"   Categories with candidates: {reference_db['selected_categories']}\")\n",
    "print(f\"   Total references selected: {total_selected}\")\n",
    "print(f\"   Average per category: {total_selected/max(reference_db['selected_categories'], 1):.1f}\")\n",
    "\n",
    "print(f\"\\nğŸ“ Generated Files:\")\n",
    "print(f\"   ğŸ—ƒï¸ Reference Database: results/reference_solutions/reference_database_auto_*.json\")\n",
    "print(f\"   ğŸ“„ Latest Database: results/reference_solutions/reference_database_latest.json\")\n",
    "print(f\"   ğŸ“Š Selection Summary: results/reference_analysis/reference_selection_summary_*.json\")\n",
    "\n",
    "print(f\"\\nğŸ”„ Next Steps for Aufgabe 4:\")\n",
    "print(f\"   1ï¸âƒ£ Reference database is ready to use\")\n",
    "print(f\"   2ï¸âƒ£ Run aufgabe4_final_evaluation.ipynb\")\n",
    "print(f\"   3ï¸âƒ£ System will automatically load best references\")\n",
    "print(f\"   4ï¸âƒ£ Student evaluation will use optimal reference for each category\")\n",
    "\n",
    "print(f\"\\nğŸ’¡ Usage Notes:\")\n",
    "print(f\"   â€¢ No manual file copying needed\")\n",
    "print(f\"   â€¢ References stay in original locations (mapped_train/)\")\n",
    "print(f\"   â€¢ JSON database contains paths to reference images\")\n",
    "print(f\"   â€¢ Evaluation system loads references via JSON database\")\n",
    "\n",
    "# Quick category overview\n",
    "if reference_db['references']:\n",
    "    print(f\"\\nğŸ“Š Quick Reference Overview:\")\n",
    "    for category, refs in reference_db['references'].items():\n",
    "        if refs:\n",
    "            best_score = refs[0].get('total_score', 0)\n",
    "            print(f\"   ğŸ“ {category}: {len(refs)} references (best: {best_score:.2f})\")\n",
    "        else:\n",
    "            print(f\"   ğŸ“ {category}: No valid references found\")\n",
    "\n",
    "print(f\"\\nğŸ† Ready for production evaluation!\")\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "# Opsiyonel: En iyi referansÄ± gÃ¶rmek istiyorsanÄ±z\n",
    "def display_best_reference_per_category(reference_db):\n",
    "    \"\"\"Her kategorinin en iyi referansÄ±nÄ± gÃ¶ster\"\"\"\n",
    "    print(\"ğŸ† BEST REFERENCE PER CATEGORY:\\n\")\n",
    "    \n",
    "    for category, refs in reference_db['references'].items():\n",
    "        if refs:\n",
    "            best_ref = refs[0]  # Ä°lk sÄ±radaki en iyi\n",
    "            print(f\"ğŸ“ {category}:\")\n",
    "            print(f\"   File: {best_ref['filename']}\")\n",
    "            print(f\"   Score: {best_ref['total_score']:.2f}\")\n",
    "            print(f\"   Confidence: {best_ref['confidence']:.2%}\")\n",
    "            print(f\"   Match: {'âœ…' if best_ref['category_match'] else 'âŒ'}\")\n",
    "            print(f\"   Dimensions: {best_ref['dimensions']}\")\n",
    "            print(f\"   Path: {best_ref['image_path']}\")\n",
    "            print()\n",
    "        else:\n",
    "            print(f\"ğŸ“ {category}: No references available\\n\")\n",
    "\n",
    "# En iyi referanslarÄ± gÃ¶ster\n",
    "display_best_reference_per_category(reference_db)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"ğŸ¯ REFERENCE SELECTION PROCESS COMPLETED\\n\")\n",
    "\n",
    "print(\"âœ… What was accomplished:\")\n",
    "print(\"   1. Analyzed training data structure\")\n",
    "print(\"   2. Evaluated reference candidates using CNN + quality metrics\")  \n",
    "print(\"   3. Automatically selected top 5 candidates per category\")\n",
    "print(\"   4. Created JSON reference database\")\n",
    "print(\"   5. Generated summary statistics\")\n",
    "\n",
    "print(\"\\nğŸ“ Generated files:\")\n",
    "print(f\"   - Reference database: {REFERENCE_OUTPUT}\")\n",
    "print(f\"   - Analysis results: {ANALYSIS_OUTPUT}\")\n",
    "print(f\"   - Latest database: reference_database_latest.json\")\n",
    "\n",
    "print(\"\\nğŸ”„ Next steps for Aufgabe 4:\")\n",
    "print(\"   1. Use JSON database for student submission comparison\")\n",
    "print(\"   2. Run aufgabe4_final_evaluation.ipynb\")\n",
    "print(\"   3. System will load references automatically from JSON\")\n",
    "print(\"   4. Generate evaluation reports for students\")\n",
    "\n",
    "print(\"\\nâš ï¸ Important notes:\")\n",
    "print(\"   - References are selected from TRAINING data, not student submissions\")\n",
    "print(\"   - Top 5 candidates available per category for flexibility\")\n",
    "print(\"   - References stay in original locations (no copying needed)\")\n",
    "print(\"   - JSON database contains all reference information and paths\")\n",
    "print(\"   - Student submissions (val/SAP) will be compared against best references\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
