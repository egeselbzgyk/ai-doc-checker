{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "# üéì Aufgabe 4 - Final Evaluation System\n",
    "\n",
    "**Vergleich mit Musterl√∂sung - Complete System Test**\n",
    "\n",
    "Bu notebook **Aufgabe 4**'√ºn final implementation'ƒ±:\n",
    "\n",
    "1. **Complete Workflow Test** - Ende-zu-Ende sistem testi\n",
    "2. **Student vs Reference** kar≈üƒ±la≈ütƒ±rmasƒ±  \n",
    "3. **Automated Grading** sistemi\n",
    "4. **Results Export** - PDF raporlar\n",
    "5. **Performance Analysis** - sistem deƒüerlendirmesi\n",
    "\n",
    "## üèÜ Das ist der finale Schritt f√ºr Aufgabe 4!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import base64\n",
    "import requests\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from PIL import Image\n",
    "from datetime import datetime\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Local imports\n",
    "from predict import predict_image\n",
    "from prompt_templates import prompt_templates, comparison_prompt\n",
    "\n",
    "print(\"‚úÖ Aufgabe 4 Final Evaluation System\")\n",
    "print(\"üéØ Ready to test complete workflow!\")\n",
    "\n",
    "# Setup paths\n",
    "VAL_DIR = r\"C:\\Users\\egese\\Desktop\\dataset\\val\\SAP\"\n",
    "RESULTS_DIR = \"results/validation_analysis/\"\n",
    "REFERENCE_DIR = \"results/reference_solutions/\"\n",
    "FINAL_OUTPUT = \"results/aufgabe4_final/\"\n",
    "\n",
    "# Create output directory\n",
    "os.makedirs(FINAL_OUTPUT, exist_ok=True)\n",
    "\n",
    "print(f\"üìÅ Validation images: {VAL_DIR}\")\n",
    "print(f\"üìä Analysis results: {RESULTS_DIR}\")\n",
    "print(f\"üéØ Reference solutions: {REFERENCE_DIR}\")\n",
    "print(f\"üèÜ Final output: {FINAL_OUTPUT}\")\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## üéØ Complete Evaluation Class\n",
    "\n",
    "Dies ist die finale Implementation von Aufgabe 4:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Aufgabe4EvaluationSystem:\n",
    "    def __init__(self, api_key):\n",
    "        \"\"\"Complete evaluation system for Aufgabe 4\"\"\"\n",
    "        self.api_key = api_key\n",
    "        self.setup_claude_api()\n",
    "        \n",
    "        # Load reference solutions\n",
    "        self.reference_solutions = {}\n",
    "        self.load_reference_database()\n",
    "        \n",
    "        # Evaluation results\n",
    "        self.evaluation_results = []\n",
    "        \n",
    "    def setup_claude_api(self):\n",
    "        \"\"\"Setup OpenRouter Claude API\"\"\"\n",
    "        self.base_url = \"https://openrouter.ai/api/v1/chat/completions\"\n",
    "        self.model = \"anthropic/claude-3-sonnet:beta\"\n",
    "        print(\"‚úÖ Claude API ready for evaluation\")\n",
    "    \n",
    "    def load_reference_database(self):\n",
    "        \"\"\"Load reference solutions from JSON files\"\"\"\n",
    "        if os.path.exists(REFERENCE_DIR):\n",
    "            ref_files = [f for f in os.listdir(REFERENCE_DIR) if f.startswith('reference_solutions_')]\n",
    "            if ref_files:\n",
    "                latest_ref = sorted(ref_files)[-1]\n",
    "                ref_path = os.path.join(REFERENCE_DIR, latest_ref)\n",
    "                \n",
    "                with open(ref_path, 'r', encoding='utf-8') as f:\n",
    "                    ref_data = json.load(f)\n",
    "                    self.reference_solutions = ref_data.get('references', {})\n",
    "                \n",
    "                print(f\"‚úÖ Loaded reference solutions: {len(self.reference_solutions)} categories\")\n",
    "                for category, refs in self.reference_solutions.items():\n",
    "                    print(f\"   üìÅ {category}: {len(refs)} reference(s)\")\n",
    "            else:\n",
    "                print(\"‚ö†Ô∏è No reference solutions found!\")\n",
    "        else:\n",
    "            print(\"‚ùå Reference directory not found!\")\n",
    "    \n",
    "    def classify_student_submission(self, image_path):\n",
    "        \"\"\"CNN classification of student submission\"\"\"\n",
    "        try:\n",
    "            predicted_class, confidence = predict_image(image_path)\n",
    "            return {\n",
    "                \"category\": predicted_class,\n",
    "                \"confidence\": float(confidence),\n",
    "                \"status\": \"success\"\n",
    "            }\n",
    "        except Exception as e:\n",
    "            return {\n",
    "                \"category\": None,\n",
    "                \"confidence\": 0.0,\n",
    "                \"status\": \"error\",\n",
    "                \"error\": str(e)\n",
    "            }\n",
    "    \n",
    "    def get_best_reference(self, category):\n",
    "        \"\"\"Get best reference for a category\"\"\"\n",
    "        if category not in self.reference_solutions:\n",
    "            return None\n",
    "        \n",
    "        references = self.reference_solutions[category]\n",
    "        if not references:\n",
    "            return None\n",
    "        \n",
    "        # Get first (best) reference\n",
    "        best_ref = references[0]\n",
    "        ref_filename = best_ref['filename']\n",
    "        ref_path = os.path.join(VAL_DIR, ref_filename)\n",
    "        \n",
    "        if os.path.exists(ref_path):\n",
    "            return {\n",
    "                \"filename\": ref_filename,\n",
    "                \"path\": ref_path,\n",
    "                \"details\": best_ref\n",
    "            }\n",
    "        return None\n",
    "    \n",
    "    def encode_image(self, image_path):\n",
    "        \"\"\"Encode image to base64\"\"\"\n",
    "        try:\n",
    "            with open(image_path, \"rb\") as image_file:\n",
    "                return base64.b64encode(image_file.read()).decode('utf-8')\n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Image encoding error: {e}\")\n",
    "            return None\n",
    "    \n",
    "    def compare_with_reference(self, student_path, reference_info, category):\n",
    "        \"\"\"Compare student submission with reference using Claude\"\"\"\n",
    "        student_b64 = self.encode_image(student_path)\n",
    "        reference_b64 = self.encode_image(reference_info['path'])\n",
    "        \n",
    "        if not student_b64 or not reference_b64:\n",
    "            return {\"error\": \"Failed to encode images\"}\n",
    "        \n",
    "        headers = {\n",
    "            \"Authorization\": f\"Bearer {self.api_key}\",\n",
    "            \"Content-Type\": \"application/json\",\n",
    "            \"HTTP-Referer\": \"http://localhost:8888\",\n",
    "            \"X-Title\": \"Aufgabe 4 Evaluation\"\n",
    "        }\n",
    "        \n",
    "        # Build comparison prompt\n",
    "        prompt = f\"\"\"\n",
    "Vergleiche das Student-Bild mit der Musterl√∂sung in der Kategorie {category}.\n",
    "\n",
    "BEWERTUNGSKRITERIEN:\n",
    "1. Kategorie-Zuordnung (0-25 Punkte)\n",
    "2. Technische Qualit√§t (0-25 Punkte) \n",
    "3. Vollst√§ndigkeit (0-25 Punkte)\n",
    "4. SAP BW Konformit√§t (0-25 Punkte)\n",
    "\n",
    "Gib eine detaillierte Bewertung als JSON zur√ºck:\n",
    "{{\n",
    "  \"kategorie_bewertung\": {{\n",
    "    \"richtige_kategorie\": true/false,\n",
    "    \"sicherheit\": 0-100,\n",
    "    \"punkte\": 0-25,\n",
    "    \"erklaerung\": \"Begr√ºndung\"\n",
    "  }},\n",
    "  \"technische_qualitaet\": {{\n",
    "    \"struktur\": 0-10,\n",
    "    \"lesbarkeit\": 0-10,\n",
    "    \"vollstaendigkeit\": 0-5,\n",
    "    \"punkte\": 0-25,\n",
    "    \"kommentar\": \"Detailbewertung\"\n",
    "  }},\n",
    "  \"inhaltliche_bewertung\": {{\n",
    "    \"fachliche_korrektheit\": 0-15,\n",
    "    \"business_kontext\": 0-10,\n",
    "    \"punkte\": 0-25,\n",
    "    \"feedback\": \"Inhaltliches Feedback\"\n",
    "  }},\n",
    "  \"sap_bw_konformitaet\": {{\n",
    "    \"standard_konform\": 0-15,\n",
    "    \"terminologie\": 0-10,\n",
    "    \"punkte\": 0-25,\n",
    "    \"anmerkungen\": \"SAP-spezifische Bewertung\"\n",
    "  }},\n",
    "  \"gesamt_bewertung\": {{\n",
    "    \"gesamtpunkte\": 0-100,\n",
    "    \"note\": 1.0-5.0,\n",
    "    \"bestanden\": true/false,\n",
    "    \"feedback\": \"Zusammenfassendes Feedback f√ºr Student\"\n",
    "  }},\n",
    "  \"verbesserungsvorschlaege\": [\n",
    "    \"Konkrete Verbesserungshinweise\"\n",
    "  ]\n",
    "}}\n",
    "\"\"\"\n",
    "        \n",
    "        data = {\n",
    "            \"model\": self.model,\n",
    "            \"max_tokens\": 2500,\n",
    "            \"temperature\": 0.1,\n",
    "            \"messages\": [\n",
    "                {\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": [\n",
    "                        {\"type\": \"text\", \"text\": \"**STUDENT SUBMISSION:**\"},\n",
    "                        {\n",
    "                            \"type\": \"image_url\",\n",
    "                            \"image_url\": {\"url\": f\"data:image/jpeg;base64,{student_b64}\"}\n",
    "                        },\n",
    "                        {\"type\": \"text\", \"text\": \"**MUSTERL√ñSUNG (REFERENCE):**\"},\n",
    "                        {\n",
    "                            \"type\": \"image_url\", \n",
    "                            \"image_url\": {\"url\": f\"data:image/jpeg;base64,{reference_b64}\"}\n",
    "                        },\n",
    "                        {\"type\": \"text\", \"text\": prompt}\n",
    "                    ]\n",
    "                }\n",
    "            ]\n",
    "        }\n",
    "        \n",
    "        try:\n",
    "            response = requests.post(self.base_url, headers=headers, json=data, timeout=120)\n",
    "            \n",
    "            if response.status_code == 200:\n",
    "                result = response.json()\n",
    "                content = result.get('choices', [{}])[0].get('message', {}).get('content', '')\n",
    "                return {\"response\": content}\n",
    "            else:\n",
    "                return {\"error\": f\"HTTP {response.status_code}: {response.text}\"}\n",
    "                \n",
    "        except Exception as e:\n",
    "            return {\"error\": f\"Request failed: {str(e)}\"}\n",
    "    \n",
    "    def parse_evaluation_response(self, response):\n",
    "        \"\"\"Parse Claude evaluation response to JSON\"\"\"\n",
    "        try:\n",
    "            if \"error\" in response:\n",
    "                return response\n",
    "            \n",
    "            text_output = response.get('response', '')\n",
    "            \n",
    "            # Extract JSON\n",
    "            start_idx = text_output.find('{')\n",
    "            end_idx = text_output.rfind('}') + 1\n",
    "            \n",
    "            if start_idx != -1 and end_idx > start_idx:\n",
    "                json_str = text_output[start_idx:end_idx]\n",
    "                parsed = json.loads(json_str)\n",
    "                return parsed\n",
    "            else:\n",
    "                return {\n",
    "                    \"error\": \"JSON not found in response\",\n",
    "                    \"raw_text\": text_output[:500]\n",
    "                }\n",
    "                \n",
    "        except json.JSONDecodeError as e:\n",
    "            return {\n",
    "                \"error\": f\"JSON parse error: {str(e)}\",\n",
    "                \"raw_response\": str(response.get('response', ''))[:500]\n",
    "            }\n",
    "    \n",
    "    def evaluate_student_submission(self, student_image_path, student_filename):\n",
    "        \"\"\"Complete evaluation of a single student submission\"\"\"\n",
    "        print(f\"üîç Evaluating: {student_filename}\")\n",
    "        \n",
    "        # Step 1: CNN Classification\n",
    "        classification = self.classify_student_submission(student_image_path)\n",
    "        if classification['status'] != 'success':\n",
    "            return {\n",
    "                \"filename\": student_filename,\n",
    "                \"status\": \"error\",\n",
    "                \"error\": \"CNN classification failed\",\n",
    "                \"classification\": classification\n",
    "            }\n",
    "        \n",
    "        category = classification['category']\n",
    "        print(f\"   üìä Classified as: {category} ({classification['confidence']:.2%})\")\n",
    "        \n",
    "        # Step 2: Get reference solution\n",
    "        reference = self.get_best_reference(category)\n",
    "        if not reference:\n",
    "            return {\n",
    "                \"filename\": student_filename,\n",
    "                \"status\": \"error\", \n",
    "                \"error\": f\"No reference solution for category {category}\",\n",
    "                \"classification\": classification\n",
    "            }\n",
    "        \n",
    "        print(f\"   üéØ Reference: {reference['filename']}\")\n",
    "        \n",
    "        # Step 3: Claude comparison\n",
    "        comparison = self.compare_with_reference(student_image_path, reference, category)\n",
    "        evaluation = self.parse_evaluation_response(comparison)\n",
    "        \n",
    "        if \"error\" in evaluation:\n",
    "            print(f\"   ‚ùå Claude evaluation failed: {evaluation['error']}\")\n",
    "        else:\n",
    "            if 'gesamt_bewertung' in evaluation:\n",
    "                score = evaluation['gesamt_bewertung'].get('gesamtpunkte', 0)\n",
    "                grade = evaluation['gesamt_bewertung'].get('note', 5.0)\n",
    "                print(f\"   ‚úÖ Score: {score}/100, Grade: {grade}\")\n",
    "            else:\n",
    "                print(f\"   ‚ö†Ô∏è Incomplete evaluation response\")\n",
    "        \n",
    "        # Compile final result\n",
    "        result = {\n",
    "            \"filename\": student_filename,\n",
    "            \"image_path\": student_image_path,\n",
    "            \"classification\": classification,\n",
    "            \"reference_used\": reference,\n",
    "            \"evaluation\": evaluation,\n",
    "            \"timestamp\": datetime.now().isoformat(),\n",
    "            \"status\": \"success\" if \"error\" not in evaluation else \"partial\"\n",
    "        }\n",
    "        \n",
    "        return result\n",
    "\n",
    "# Initialize evaluation system\n",
    "API_KEY = \"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\"\n",
    "\n",
    "try:\n",
    "    evaluator = Aufgabe4EvaluationSystem(API_KEY)\n",
    "    print(\"\\nüéì Aufgabe 4 Evaluation System ready!\")\n",
    "    print(f\"üìä Categories with references: {len(evaluator.reference_solutions)}\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Evaluation system setup failed: {e}\")\n",
    "    evaluator = None\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
