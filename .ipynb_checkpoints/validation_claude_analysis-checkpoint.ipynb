{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "# üìä Validation Set Batch Analysis - Claude Sonnet 3\n",
    "\n",
    "Bu notebook ile `dataset/val/SAP/` klas√∂r√ºndeki unlabeled g√∂rselleri:\n",
    "1. **EfficientNet-B0** ile classify edeceƒüiz\n",
    "2. **Claude Sonnet 3 Vision** ile detaylƒ± analiz yapacaƒüƒ±z\n",
    "3. **Student submissions** i√ßin category statistics √ßƒ±karacaƒüƒ±z\n",
    "4. **Reference solution** adaylarƒ± belirleyeceƒüiz\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## üîß Setup ve Import'lar\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'anthropic'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 15\u001b[0m\n\u001b[0;32m     12\u001b[0m warnings\u001b[38;5;241m.\u001b[39mfilterwarnings(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     14\u001b[0m \u001b[38;5;66;03m# Anthropic API\u001b[39;00m\n\u001b[1;32m---> 15\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01manthropic\u001b[39;00m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;66;03m# Local imports\u001b[39;00m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpredict\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m predict_image\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'anthropic'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import base64\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "import time\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Anthropic API\n",
    "import anthropic\n",
    "\n",
    "# Local imports\n",
    "from predict import predict_image\n",
    "from prompt_templates import prompt_templates\n",
    "\n",
    "print(\"‚úÖ All imports successful!\")\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## ü§ñ Claude Sonnet 3 API Setup\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ClaudeSonnetAnalyzer:\n",
    "    def __init__(self, api_key=None):\n",
    "        \"\"\"\n",
    "        Claude Sonnet 3 Vision API client\n",
    "        \n",
    "        Args:\n",
    "            api_key: Anthropic API key\n",
    "        \"\"\"\n",
    "        # API key setup\n",
    "        key = api_key or os.getenv('ANTHROPIC_API_KEY')\n",
    "        if not key:\n",
    "            raise ValueError(\"‚ùå Anthropic API key required!\")\n",
    "        \n",
    "        self.client = anthropic.Anthropic(api_key=key)\n",
    "        self.model = \"claude-3-sonnet-20240229\"  # Claude 3 Sonnet with vision\n",
    "        \n",
    "        print(\"‚úÖ Claude Sonnet 3 API initialized\")\n",
    "    \n",
    "    def encode_image(self, image_path):\n",
    "        \"\"\"G√∂rseli base64'e √ßevir\"\"\"\n",
    "        try:\n",
    "            with open(image_path, \"rb\") as image_file:\n",
    "                return base64.b64encode(image_file.read()).decode('utf-8')\n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Image encoding error: {e}\")\n",
    "            return None\n",
    "    \n",
    "    def get_image_media_type(self, image_path):\n",
    "        \"\"\"G√∂rsel formatƒ±nƒ± belirle\"\"\"\n",
    "        ext = os.path.splitext(image_path)[1].lower()\n",
    "        if ext in ['.jpg', '.jpeg']:\n",
    "            return \"image/jpeg\"\n",
    "        elif ext == '.png':\n",
    "            return \"image/png\"\n",
    "        elif ext == '.gif':\n",
    "            return \"image/gif\"\n",
    "        elif ext == '.webp':\n",
    "            return \"image/webp\"\n",
    "        else:\n",
    "            return \"image/jpeg\"  # Default\n",
    "    \n",
    "    def analyze_image(self, image_path, prompt, max_retries=3):\n",
    "        \"\"\"Claude Sonnet 3 ile g√∂rsel analizi\"\"\"\n",
    "        base64_image = self.encode_image(image_path)\n",
    "        if not base64_image:\n",
    "            return {\"error\": \"Failed to encode image\"}\n",
    "        \n",
    "        media_type = self.get_image_media_type(image_path)\n",
    "        \n",
    "        for attempt in range(max_retries):\n",
    "            try:\n",
    "                message = self.client.messages.create(\n",
    "                    model=self.model,\n",
    "                    max_tokens=1500,\n",
    "                    temperature=0.1,\n",
    "                    messages=[\n",
    "                        {\n",
    "                            \"role\": \"user\",\n",
    "                            \"content\": [\n",
    "                                {\n",
    "                                    \"type\": \"image\",\n",
    "                                    \"source\": {\n",
    "                                        \"type\": \"base64\",\n",
    "                                        \"media_type\": media_type,\n",
    "                                        \"data\": base64_image\n",
    "                                    }\n",
    "                                },\n",
    "                                {\n",
    "                                    \"type\": \"text\",\n",
    "                                    \"text\": prompt\n",
    "                                }\n",
    "                            ]\n",
    "                        }\n",
    "                    ]\n",
    "                )\n",
    "                \n",
    "                return {\"response\": message.content[0].text}\n",
    "                \n",
    "            except anthropic.RateLimitError:\n",
    "                print(f\"‚è≥ Rate limit hit, waiting... (attempt {attempt + 1})\")\n",
    "                time.sleep(10)\n",
    "                continue\n",
    "            except anthropic.APIError as e:\n",
    "                print(f\"‚ùå API Error: {e}\")\n",
    "                return {\"error\": f\"API Error: {str(e)}\"}\n",
    "            except Exception as e:\n",
    "                print(f\"‚ùå Request error: {e}\")\n",
    "                if attempt < max_retries - 1:\n",
    "                    time.sleep(5)\n",
    "                    continue\n",
    "                return {\"error\": f\"Request failed: {str(e)}\"}\n",
    "        \n",
    "        return {\"error\": \"Max retries exceeded\"}\n",
    "    \n",
    "    def parse_json_response(self, response):\n",
    "        \"\"\"Claude response'u JSON olarak parse et\"\"\"\n",
    "        try:\n",
    "            if \"error\" in response:\n",
    "                return response\n",
    "            \n",
    "            # Claude response'undan text kƒ±smƒ±nƒ± al\n",
    "            text_output = response.get('response', '')\n",
    "            \n",
    "            # JSON kƒ±smƒ±nƒ± extract et (curly braces arasƒ±nda)\n",
    "            start_idx = text_output.find('{')\n",
    "            end_idx = text_output.rfind('}') + 1\n",
    "            \n",
    "            if start_idx != -1 and end_idx > start_idx:\n",
    "                json_str = text_output[start_idx:end_idx]\n",
    "                parsed = json.loads(json_str)\n",
    "                return parsed\n",
    "            else:\n",
    "                return {\n",
    "                    \"error\": \"JSON not found in response\", \n",
    "                    \"raw_text\": text_output[:500]  # ƒ∞lk 500 char\n",
    "                }\n",
    "                \n",
    "        except json.JSONDecodeError as e:\n",
    "            return {\n",
    "                \"error\": f\"JSON parse error: {str(e)}\", \n",
    "                \"raw_response\": str(response.get('response', ''))[:500]\n",
    "            }\n",
    "        except Exception as e:\n",
    "            return {\n",
    "                \"error\": f\"Unexpected error: {str(e)}\", \n",
    "                \"raw_response\": str(response)[:500]\n",
    "            }\n",
    "\n",
    "# API'yi initialize edin - API key'inizi buraya girin\n",
    "API_KEY = \"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\"\n",
    "\n",
    "try:\n",
    "    claude_analyzer = ClaudeSonnetAnalyzer(api_key=API_KEY)\n",
    "    print(\"üéØ Claude Sonnet 3 ready to analyze images!\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Setup failed: {e}\")\n",
    "    print(\"üí° Make sure you have: pip install anthropic\")\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## üóÇÔ∏è Dataset Kurulumu\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset paths\n",
    "VAL_DIR = r\"C:\\Users\\egese\\Desktop\\dataset\\val\\SAP\"\n",
    "OUTPUT_DIR = \"results/validation_analysis/\"\n",
    "\n",
    "# Output directory olu≈ütur\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "# Validation set'teki g√∂rselleri listele\n",
    "image_files = [f for f in os.listdir(VAL_DIR) \n",
    "               if f.lower().endswith(('.png', '.jpg', '.jpeg'))]\n",
    "\n",
    "print(f\"üìÅ Validation directory: {VAL_DIR}\")\n",
    "print(f\"üìä Total images found: {len(image_files)}\")\n",
    "print(f\"üíæ Output directory: {OUTPUT_DIR}\")\n",
    "\n",
    "# ƒ∞lk birka√ß dosya adƒ±nƒ± g√∂ster\n",
    "print(\"\\nüìã Sample files:\")\n",
    "for i, filename in enumerate(image_files[:5]):\n",
    "    print(f\"  {i+1}. {filename}\")\n",
    "if len(image_files) > 5:\n",
    "    print(f\"  ... and {len(image_files) - 5} more\")\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## üß™ Test Run - Tek G√∂rsel Analizi\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_single_image_analysis(image_filename):\n",
    "    \"\"\"Tek g√∂rsel ile test analizi\"\"\"\n",
    "    image_path = os.path.join(VAL_DIR, image_filename)\n",
    "    \n",
    "    print(f\"üîç Testing with: {image_filename}\")\n",
    "    \n",
    "    try:\n",
    "        # 1. CNN Prediction\n",
    "        print(\"1Ô∏è‚É£ CNN Analysis...\")\n",
    "        predicted_class, confidence = predict_image(image_path)\n",
    "        print(f\"   ‚úÖ CNN Result: {predicted_class} ({confidence:.2%} confidence)\")\n",
    "        \n",
    "        # 2. Claude Vision Analysis\n",
    "        print(\"2Ô∏è‚É£ Claude Vision Analysis...\")\n",
    "        prompt = prompt_templates[predicted_class]\n",
    "        claude_response = claude_analyzer.analyze_image(image_path, prompt)\n",
    "        claude_analysis = claude_analyzer.parse_json_response(claude_response)\n",
    "        \n",
    "        print(\"   ‚úÖ Claude Analysis completed\")\n",
    "        \n",
    "        # 3. Results\n",
    "        result = {\n",
    "            \"filename\": image_filename,\n",
    "            \"cnn_prediction\": predicted_class,\n",
    "            \"cnn_confidence\": float(confidence),\n",
    "            \"claude_analysis\": claude_analysis,\n",
    "            \"timestamp\": datetime.now().isoformat(),\n",
    "            \"status\": \"success\"\n",
    "        }\n",
    "        \n",
    "        # Sonu√ßlarƒ± g√ºzel formatta yazdƒ±r\n",
    "        print(\"\\nüìä ANALYSIS RESULTS:\")\n",
    "        print(f\"   Category: {predicted_class}\")\n",
    "        print(f\"   CNN Confidence: {confidence:.2%}\")\n",
    "        \n",
    "        if \"error\" not in claude_analysis:\n",
    "            if \"gesamt_score\" in claude_analysis:\n",
    "                print(f\"   Claude Score: {claude_analysis['gesamt_score']}/10\")\n",
    "            print(\"   Claude Analysis: ‚úÖ Success\")\n",
    "        else:\n",
    "            print(f\"   Claude Analysis: ‚ùå {claude_analysis['error']}\")\n",
    "        \n",
    "        return result\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Test failed: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "# Test ile ilk g√∂rsel\n",
    "if image_files:\n",
    "    test_result = test_single_image_analysis(image_files[0])\n",
    "    \n",
    "    # Test success kontrol√º - hem CNN hem Claude ba≈üarƒ±lƒ± olmalƒ±\n",
    "    if test_result and test_result.get('status') == 'success':\n",
    "        claude_analysis = test_result.get('claude_analysis', {})\n",
    "        claude_success = 'error' not in claude_analysis\n",
    "        \n",
    "        if claude_success:\n",
    "            print(\"\\nüéâ Test successful! Both CNN and Claude working. Ready for batch processing.\")\n",
    "        else:\n",
    "            print(\"\\n‚ö†Ô∏è Test partially successful: CNN works but Claude failed.\")\n",
    "            print(\"üîß You can still continue with CNN-only analysis if needed.\")\n",
    "    else:\n",
    "        print(\"\\n‚ö†Ô∏è Test failed. Please check configuration.\")\n",
    "else:\n",
    "    print(\"‚ùå No images found in validation directory!\")\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## üöÄ Batch Processing - T√ºm Validation Set\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_single_image(image_filename):\n",
    "    \"\"\"Tek g√∂rsel i√ßin tam analiz\"\"\"\n",
    "    image_path = os.path.join(VAL_DIR, image_filename)\n",
    "    \n",
    "    try:\n",
    "        # 1. CNN Prediction\n",
    "        predicted_class, confidence = predict_image(image_path)\n",
    "        \n",
    "        # 2. Claude Vision Analysis\n",
    "        prompt = prompt_templates[predicted_class]\n",
    "        claude_response = claude_analyzer.analyze_image(image_path, prompt)\n",
    "        claude_analysis = claude_analyzer.parse_json_response(claude_response)\n",
    "        \n",
    "        result = {\n",
    "            \"filename\": image_filename,\n",
    "            \"image_path\": image_path,\n",
    "            \"cnn_prediction\": predicted_class,\n",
    "            \"cnn_confidence\": float(confidence),\n",
    "            \"claude_analysis\": claude_analysis,\n",
    "            \"timestamp\": datetime.now().isoformat(),\n",
    "            \"status\": \"success\"\n",
    "        }\n",
    "        \n",
    "        return result\n",
    "        \n",
    "    except Exception as e:\n",
    "        return {\n",
    "            \"filename\": image_filename,\n",
    "            \"status\": \"error\",\n",
    "            \"error\": str(e),\n",
    "            \"timestamp\": datetime.now().isoformat()\n",
    "        }\n",
    "\n",
    "def run_batch_analysis(limit=None, save_every=10):\n",
    "    \"\"\"Batch analiz - t√ºm validation set\"\"\"\n",
    "    \n",
    "    # Limit uygula\n",
    "    files_to_process = image_files[:limit] if limit else image_files\n",
    "    \n",
    "    print(f\"üîÑ Starting batch analysis of {len(files_to_process)} images\")\n",
    "    print(f\"üíæ Saving intermediate results every {save_every} images\")\n",
    "    print(f\"ü§ñ Using Claude Sonnet 3 Vision API\")\n",
    "    \n",
    "    all_results = []\n",
    "    \n",
    "    # Progress bar ile i≈ülem\n",
    "    for i, image_file in enumerate(tqdm(files_to_process, desc=\"Processing images\")):\n",
    "        \n",
    "        result = process_single_image(image_file)\n",
    "        all_results.append(result)\n",
    "        \n",
    "        # Status yazdƒ±r\n",
    "        if result.get('status') == 'success':\n",
    "            cnn_pred = result['cnn_prediction']\n",
    "            cnn_conf = result['cnn_confidence']\n",
    "            claude_status = \"‚úÖ\" if 'error' not in result.get('claude_analysis', {}) else \"‚ùå\"\n",
    "            print(f\"   {i+1:3d}. {image_file[:30]:30s} | {cnn_pred:15s} ({cnn_conf:.2%}) | Claude: {claude_status}\")\n",
    "        else:\n",
    "            print(f\"   {i+1:3d}. {image_file[:30]:30s} | ‚ùå ERROR\")\n",
    "        \n",
    "        # Interim save\n",
    "        if (i + 1) % save_every == 0:\n",
    "            interim_filename = f\"interim_results_{i+1}.json\"\n",
    "            interim_path = os.path.join(OUTPUT_DIR, interim_filename)\n",
    "            \n",
    "            with open(interim_path, 'w', encoding='utf-8') as f:\n",
    "                json.dump(all_results, f, ensure_ascii=False, indent=2)\n",
    "            \n",
    "            # Progress info\n",
    "            success_count = len([r for r in all_results if r.get('status') == 'success'])\n",
    "            claude_success = len([r for r in all_results if r.get('status') == 'success' and 'error' not in r.get('claude_analysis', {})])\n",
    "            print(f\"\\nüìä Progress: {i+1}/{len(files_to_process)} | Success: {success_count} | Claude Success: {claude_success} | Saved: {interim_filename}\")\n",
    "            \n",
    "            # Rate limiting - Claude API i√ßin\n",
    "            if i < len(files_to_process) - 1:  # Son deƒüilse\n",
    "                print(\"‚è≥ Pausing 2 seconds for rate limiting...\")\n",
    "                time.sleep(2)\n",
    "    \n",
    "    return all_results\n",
    "\n",
    "# BATCH PROCESSING BA≈ûLAT\n",
    "print(\"‚ö° Choose your processing option:\")\n",
    "print(\"1. Test run (first 5 images)\")\n",
    "print(\"2. Medium run (first 20 images)\")\n",
    "print(\"3. Full run (all images)\")\n",
    "\n",
    "# Test run ile ba≈üla - Bu deƒüeri deƒüi≈ütirerek full run yapabilirsiniz\n",
    "PROCESSING_LIMIT = 10  # 10 g√∂rsel ile ba≈ülayalƒ±m\n",
    "\n",
    "print(f\"\\nüöÄ Starting processing with limit: {PROCESSING_LIMIT}\")\n",
    "batch_results = run_batch_analysis(limit=PROCESSING_LIMIT)\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## üíæ Sonu√ßlarƒ± Kaydetme ve Analiz\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final sonu√ßlarƒ± kaydet\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "final_filename = f\"validation_claude_results_{timestamp}.json\"\n",
    "final_path = os.path.join(OUTPUT_DIR, final_filename)\n",
    "\n",
    "with open(final_path, 'w', encoding='utf-8') as f:\n",
    "    json.dump(batch_results, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "print(f\"‚úÖ Final results saved: {final_path}\")\n",
    "print(f\"üìÅ File size: {os.path.getsize(final_path) / 1024:.1f} KB\")\n",
    "\n",
    "# Analiz fonksiyonu\n",
    "def analyze_batch_results(results):\n",
    "    \"\"\"Batch sonu√ßlarƒ±nƒ±n detaylƒ± analizi\"\"\"\n",
    "    \n",
    "    successful_results = [r for r in results if r.get('status') == 'success']\n",
    "    error_count = len(results) - len(successful_results)\n",
    "    \n",
    "    print(\"=\"*60)\n",
    "    print(\"üìä VALIDATION SET ANALYSIS REPORT - CLAUDE SONNET 3\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    print(f\"\\nüìà Processing Summary:\")\n",
    "    print(f\"   Total Images: {len(results)}\")\n",
    "    print(f\"   Successful: {len(successful_results)}\")\n",
    "    print(f\"   Errors: {error_count}\")\n",
    "    print(f\"   Success Rate: {len(successful_results)/len(results)*100:.1f}%\")\n",
    "    \n",
    "    if not successful_results:\n",
    "        print(\"‚ùå No successful results to analyze!\")\n",
    "        return\n",
    "    \n",
    "    # Claude success rate\n",
    "    claude_successful = [r for r in successful_results if 'error' not in r.get('claude_analysis', {})]\n",
    "    claude_success_rate = len(claude_successful) / len(successful_results) * 100\n",
    "    print(f\"   Claude Success Rate: {claude_success_rate:.1f}%\")\n",
    "    \n",
    "    # Kategori istatistikleri\n",
    "    category_stats = {}\n",
    "    all_confidences = []\n",
    "    all_claude_scores = []\n",
    "    \n",
    "    for result in successful_results:\n",
    "        category = result['cnn_prediction']\n",
    "        confidence = result['cnn_confidence']\n",
    "        all_confidences.append(confidence)\n",
    "        \n",
    "        if category not in category_stats:\n",
    "            category_stats[category] = {\n",
    "                'count': 0,\n",
    "                'confidences': [],\n",
    "                'claude_scores': [],\n",
    "            }\n",
    "        \n",
    "        category_stats[category]['count'] += 1\n",
    "        category_stats[category]['confidences'].append(confidence)\n",
    "        \n",
    "        # Claude analysis kontrol et\n",
    "        claude_analysis = result.get('claude_analysis', {})\n",
    "        if 'error' not in claude_analysis and 'gesamt_score' in claude_analysis:\n",
    "            score = claude_analysis['gesamt_score']\n",
    "            category_stats[category]['claude_scores'].append(score)\n",
    "            all_claude_scores.append(score)\n",
    "    \n",
    "    # Kategori ba≈üƒ±na istatistikler\n",
    "    print(f\"\\nüîç Category Analysis:\")\n",
    "    print(\"-\" * 60)\n",
    "    \n",
    "    for category, stats in sorted(category_stats.items()):\n",
    "        avg_conf = sum(stats['confidences']) / len(stats['confidences'])\n",
    "        avg_score = sum(stats['claude_scores']) / len(stats['claude_scores']) if stats['claude_scores'] else 0\n",
    "        claude_success = len(stats['claude_scores']) / stats['count'] * 100\n",
    "        \n",
    "        print(f\"\\nüìÅ {category}:\")\n",
    "        print(f\"   Images: {stats['count']}\")\n",
    "        print(f\"   Avg CNN Confidence: {avg_conf:.2%}\")\n",
    "        print(f\"   Avg Claude Score: {avg_score:.1f}/10\")\n",
    "        print(f\"   Claude Success Rate: {claude_success:.1f}%\")\n",
    "    \n",
    "    # Genel istatistikler\n",
    "    print(f\"\\nüìä Overall Statistics:\")\n",
    "    print(\"-\" * 30)\n",
    "    if all_confidences:\n",
    "        print(f\"   Avg CNN Confidence: {sum(all_confidences)/len(all_confidences):.2%}\")\n",
    "        print(f\"   Min CNN Confidence: {min(all_confidences):.2%}\")\n",
    "        print(f\"   Max CNN Confidence: {max(all_confidences):.2%}\")\n",
    "    \n",
    "    if all_claude_scores:\n",
    "        print(f\"   Avg Claude Score: {sum(all_claude_scores)/len(all_claude_scores):.1f}/10\")\n",
    "        print(f\"   Min Claude Score: {min(all_claude_scores):.1f}/10\")\n",
    "        print(f\"   Max Claude Score: {max(all_claude_scores):.1f}/10\")\n",
    "    \n",
    "    return category_stats\n",
    "\n",
    "# Analizi √ßalƒ±≈ütƒ±r\n",
    "category_statistics = analyze_batch_results(batch_results)\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## üéØ Reference Solution Candidates\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def identify_reference_candidates(results, top_n=3):\n",
    "    \"\"\"Her kategoriden en iyi √∂rnekleri referans aday olarak se√ß\"\"\"\n",
    "    \n",
    "    successful_results = [r for r in results if r.get('status') == 'success']\n",
    "    \n",
    "    if not successful_results:\n",
    "        print(\"‚ùå No successful results for reference selection!\")\n",
    "        return {}\n",
    "    \n",
    "    reference_candidates = {}\n",
    "    \n",
    "    # Kategori ba≈üƒ±na grup\n",
    "    by_category = {}\n",
    "    for result in successful_results:\n",
    "        category = result['cnn_prediction']\n",
    "        if category not in by_category:\n",
    "            by_category[category] = []\n",
    "        by_category[category].append(result)\n",
    "    \n",
    "    print(\"üéØ REFERENCE SOLUTION CANDIDATES - CLAUDE ANALYZED\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    for category, items in by_category.items():\n",
    "        print(f\"\\nüìÅ {category} ({len(items)} images):\")\n",
    "        \n",
    "        # Kombinasyon skoru: CNN confidence + Claude score\n",
    "        scored_items = []\n",
    "        for item in items:\n",
    "            cnn_conf = item['cnn_confidence']\n",
    "            claude_analysis = item.get('claude_analysis', {})\n",
    "            \n",
    "            if 'error' not in claude_analysis and 'gesamt_score' in claude_analysis:\n",
    "                claude_score = claude_analysis['gesamt_score'] / 10  # 0-1 aralƒ±ƒüƒ±na normalize\n",
    "                combined_score = (cnn_conf * 0.3) + (claude_score * 0.7)  # Claude'a daha √ßok aƒüƒ±rlƒ±k\n",
    "            else:\n",
    "                combined_score = cnn_conf * 0.5  # Sadece CNN score, penalty\n",
    "            \n",
    "            scored_items.append((item, combined_score))\n",
    "        \n",
    "        # En y√ºksek skorlular\n",
    "        top_items = sorted(scored_items, key=lambda x: x[1], reverse=True)[:top_n]\n",
    "        reference_candidates[category] = []\n",
    "        \n",
    "        for i, (item, score) in enumerate(top_items, 1):\n",
    "            reference_candidates[category].append(item)\n",
    "            \n",
    "            claude_info = \"\"\n",
    "            claude_analysis = item.get('claude_analysis', {})\n",
    "            if 'gesamt_score' in claude_analysis:\n",
    "                claude_info = f\", Claude: {claude_analysis['gesamt_score']:.1f}/10\"\n",
    "            elif 'error' in claude_analysis:\n",
    "                claude_info = f\", Claude: ERROR\"\n",
    "            \n",
    "            print(f\"   {i}. {item['filename']}\")\n",
    "            print(f\"      Combined Score: {score:.3f} (CNN: {item['cnn_confidence']:.2%}{claude_info})\")\n",
    "    \n",
    "    return reference_candidates\n",
    "\n",
    "# Reference candidates se√ß\n",
    "reference_candidates = identify_reference_candidates(batch_results, top_n=3)\n",
    "\n",
    "# Sonu√ßlarƒ± kaydet\n",
    "reference_filename = f\"reference_candidates_claude_{timestamp}.json\"\n",
    "reference_path = os.path.join(OUTPUT_DIR, reference_filename)\n",
    "\n",
    "with open(reference_path, 'w', encoding='utf-8') as f:\n",
    "    json.dump(reference_candidates, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "print(f\"\\n‚úÖ Reference candidates saved: {reference_path}\")\n",
    "\n",
    "# Summary raporu\n",
    "summary = {\n",
    "    \"analysis_timestamp\": timestamp,\n",
    "    \"model_used\": \"Claude Sonnet 3 + EfficientNet-B0\",\n",
    "    \"total_images_processed\": len(batch_results),\n",
    "    \"successful_analyses\": len([r for r in batch_results if r.get('status') == 'success']),\n",
    "    \"claude_successful_analyses\": len([r for r in batch_results if r.get('status') == 'success' and 'error' not in r.get('claude_analysis', {})]),\n",
    "    \"categories_found\": list(reference_candidates.keys()),\n",
    "    \"reference_candidates_per_category\": {k: len(v) for k, v in reference_candidates.items()},\n",
    "    \"files_generated\": {\n",
    "        \"full_results\": final_filename,\n",
    "        \"reference_candidates\": reference_filename\n",
    "    }\n",
    "}\n",
    "\n",
    "summary_filename = f\"analysis_summary_claude_{timestamp}.json\"\n",
    "summary_path = os.path.join(OUTPUT_DIR, summary_filename)\n",
    "\n",
    "with open(summary_path, 'w', encoding='utf-8') as f:\n",
    "    json.dump(summary, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "print(f\"üìã Summary saved: {summary_path}\")\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## üéâ Sonu√ß ve Sonraki Adƒ±mlar\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"üéâ VALIDATION SET ANALYSIS COMPLETED - CLAUDE SONNET 3!\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Detaylƒ± sonu√ß √∂zeti\n",
    "total_processed = len(batch_results)\n",
    "successful = len([r for r in batch_results if r.get('status') == 'success'])\n",
    "claude_successful = len([r for r in batch_results if r.get('status') == 'success' and 'error' not in r.get('claude_analysis', {})])\n",
    "\n",
    "print(f\"\\nüìä Analysis Summary:\")\n",
    "print(f\"   ‚úÖ Total Processed: {total_processed} images\")\n",
    "print(f\"   üìä CNN Successful: {successful} ({successful/total_processed*100:.1f}%)\")\n",
    "print(f\"   ü§ñ Claude Successful: {claude_successful} ({claude_successful/total_processed*100:.1f}%)\")\n",
    "print(f\"   üìÅ Categories found: {len(reference_candidates)} categories\")\n",
    "print(f\"   üéØ Reference candidates: {sum(len(v) for v in reference_candidates.values())} total\")\n",
    "\n",
    "print(f\"\\nüíæ Files Generated:\")\n",
    "print(f\"   üìÑ {final_filename} - Full analysis results\")\n",
    "print(f\"   üéØ {reference_filename} - Reference solution candidates\")\n",
    "print(f\"   üìã {summary_filename} - Analysis summary\")\n",
    "\n",
    "print(f\"\\nüöÄ Next Steps for Aufgabe 4:\")\n",
    "print(f\"   1Ô∏è‚É£ Review reference candidates manually\")\n",
    "print(f\"   2Ô∏è‚É£ Select final Musterl√∂sung for each category\")\n",
    "print(f\"   3Ô∏è‚É£ Implement comparison engine using comparison_prompt\")\n",
    "print(f\"   4Ô∏è‚É£ Test student vs reference comparison with Claude\")\n",
    "\n",
    "print(f\"\\nüí° Advantages of Claude Sonnet 3:\")\n",
    "print(f\"   ‚Ä¢ Excellent vision capabilities\")\n",
    "print(f\"   ‚Ä¢ Consistent JSON output parsing\")\n",
    "print(f\"   ‚Ä¢ High-quality analysis of SAP screenshots\")\n",
    "print(f\"   ‚Ä¢ Perfect for comparison tasks\")\n",
    "\n",
    "print(\"\\nüîß Ready for Aufgabe 4 - Comparison Engine with Claude!\")\n",
    "\n",
    "# Quick stats per category\n",
    "if reference_candidates:\n",
    "    print(f\"\\nüìä Quick Category Overview:\")\n",
    "    for category, candidates in reference_candidates.items():\n",
    "        print(f\"   üìÅ {category}: {len(candidates)} reference candidates\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîÑ Checking anthropic package...\n",
      "üì¶ Installing anthropic package...\n"
     ]
    }
   ],
   "source": [
    "# üîß Anthropic Paketi Kurulumu\n",
    "# Bu h√ºcreyi sadece ilk √ßalƒ±≈ütƒ±rmada kullanƒ±n\n",
    "\n",
    "import subprocess\n",
    "import sys\n",
    "\n",
    "def install_package(package):\n",
    "    \"\"\"Paketi jupyter notebook i√ßinden kur\"\"\"\n",
    "    try:\n",
    "        subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", package])\n",
    "        print(f\"‚úÖ {package} successfully installed!\")\n",
    "        return True\n",
    "    except subprocess.CalledProcessError as e:\n",
    "        print(f\"‚ùå Failed to install {package}: {e}\")\n",
    "        return False\n",
    "\n",
    "# Anthropic paketi kurulumu\n",
    "print(\"üîÑ Checking anthropic package...\")\n",
    "try:\n",
    "    import anthropic\n",
    "    print(\"‚úÖ Anthropic already installed!\")\n",
    "except ImportError:\n",
    "    print(\"üì¶ Installing anthropic package...\")\n",
    "    success = install_package(\"anthropic\")\n",
    "    if success:\n",
    "        print(\"üîÑ Restarting kernel may be required...\")\n",
    "    else:\n",
    "        print(\"‚ùå Manual installation required. Please run in terminal:\")\n",
    "        print(\"   py -m pip install anthropic\")\n",
    "        print(\"   OR python -m pip install anthropic\")\n",
    "        print(\"   OR pip install anthropic\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
